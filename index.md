---
layout: default
title: "LLM 课程 2025"
---

# 课程信息

<div class="course-info" markdown="1">
- **授课教师**: 袁坤，文再文  
- **助教**: 李四  
- **学期**: 2025 春季  
- **上课时间**: 每周三 9:00–11:50  
- **地点**: 三层报告厅
</div>

<hr>

# 课程大纲

<div class="course-block">
  <h2>Lecture 1: 数值代数基础</h2>
  <p>
    Introduction to large language models  
    [<a href="lectures/lecture1-slides1.pdf">Slides1</a>]  
    [<a href="lectures/lecture1-slides2.pdf">Slides2</a>]
  </p>
  <div class="readings">
    <strong>Reading:</strong>
    <ul>
      <li>Andrej Karpathy, <em>State of GPT</em></li>
      <li>Andrej Karpathy, <em>The busy person’s intro to LLM</em></li>
    </ul>
  </div>
</div>

<div class="course-block">
  <h2>Lecture 2: Machine Learning 基础</h2>
  <p>
    Review of ML foundations  
    [<a href="lectures/lecture2-slides.pdf">Slides</a>]
  </p>
  <div class="readings">
    <strong>Reading:</strong>
    <ul>
      <li>Goodfellow et al., <em>Deep Learning</em>, Chapter 1</li>
      <li>Ng, <em>Machine Learning Yearning</em></li>
    </ul>
  </div>
</div>

<div class="course-block">
  <h2>Lecture 3: Transformer 架构</h2>
  <p>
    Deep dive into the Transformer model  
    [<a href="lectures/lecture3-slides.pdf">Slides</a>]
  </p>
  <div class="readings">
    <strong>Reading:</strong>
    <ul>
      <li>Vaswani et al., <em>Attention Is All You Need</em></li>
      <li>Annotated Transformer tutorial</li>
    </ul>
  </div>
</div>

<!-- 你可以继续加 Lecture 4, 5 ... -->
